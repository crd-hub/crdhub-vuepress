<h3 id="container.google.kubeform.com/v1alpha1.NodePool">NodePool
</h3>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>apiVersion</code><br/>
string</td>
<td>
<code>
container.google.kubeform.com/v1alpha1
</code>
</td>
</tr>
<tr>
<td>
<code>kind</code><br/>
string
</td>
<td><code>NodePool</code></td>
</tr>
<tr>
<td>
<code>metadata</code><br/>
<em>
<a href="https://v1-21.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.21/#objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
</a>
</em>
</td>
<td>
Refer to the Kubernetes API documentation for the fields of the
<code>metadata</code> field.
</td>
</tr>
<tr>
<td>
<code>spec</code><br/>
<em>
<a href="#container.google.kubeform.com/v1alpha1.NodePoolSpec">
NodePoolSpec
</a>
</em>
</td>
<td>
<br/>
<br/>
<table>
<tr>
<td>
<code>state</code><br/>
<em>
<a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecResource">
NodePoolSpecResource
</a>
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>resource</code><br/>
<em>
<a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecResource">
NodePoolSpecResource
</a>
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>updatePolicy</code><br/>
<em>
kubeform.dev/apimachinery/api/v1alpha1.UpdatePolicy
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>terminationPolicy</code><br/>
<em>
kubeform.dev/apimachinery/api/v1alpha1.TerminationPolicy
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>providerRef</code><br/>
<em>
<a href="https://v1-21.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.21/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td>
<code>status</code><br/>
<em>
<a href="#container.google.kubeform.com/v1alpha1.NodePoolStatus">
NodePoolStatus
</a>
</em>
</td>
<td>
<br/>
<br/>
<table>
<tr>
<td>
<code>observedGeneration</code><br/>
<em>
int64
</em>
</td>
<td>
<em>(Optional)</em>
<p>Resource generation, which is updated on mutation by the API Server.</p>
</td>
</tr>
<tr>
<td>
<code>phase</code><br/>
<em>
sigs.k8s.io/cli-utils/pkg/kstatus/status.Status
</em>
</td>
<td>
<em>(Optional)</em>
</td>
</tr>
<tr>
<td>
<code>conditions</code><br/>
<em>
[]kmodules.xyz/client-go/api/v1.Condition
</em>
</td>
<td>
<em>(Optional)</em>
</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
<h3 id="container.google.kubeform.com/v1alpha1.NodePoolSpec">NodePoolSpec
</h3>
<p>
(<em>Appears on:</em><a href="#container.google.kubeform.com/v1alpha1.NodePool">NodePool</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>state</code><br/>
<em>
<a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecResource">
NodePoolSpecResource
</a>
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>resource</code><br/>
<em>
<a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecResource">
NodePoolSpecResource
</a>
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>updatePolicy</code><br/>
<em>
kubeform.dev/apimachinery/api/v1alpha1.UpdatePolicy
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>terminationPolicy</code><br/>
<em>
kubeform.dev/apimachinery/api/v1alpha1.TerminationPolicy
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>providerRef</code><br/>
<em>
<a href="https://v1-21.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.21/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
</td>
</tr>
</tbody>
</table>
<h3 id="container.google.kubeform.com/v1alpha1.NodePoolSpecAutoscaling">NodePoolSpecAutoscaling
</h3>
<p>
(<em>Appears on:</em><a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecResource">NodePoolSpecResource</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>maxNodeCount</code><br/>
<em>
int64
</em>
</td>
<td>
<p>Maximum number of nodes in the NodePool. Must be &gt;= min_node_count.</p>
</td>
</tr>
<tr>
<td>
<code>minNodeCount</code><br/>
<em>
int64
</em>
</td>
<td>
<p>Minimum number of nodes in the NodePool. Must be &gt;=0 and &lt;= max_node_count.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="container.google.kubeform.com/v1alpha1.NodePoolSpecManagement">NodePoolSpecManagement
</h3>
<p>
(<em>Appears on:</em><a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecResource">NodePoolSpecResource</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>autoRepair</code><br/>
<em>
bool
</em>
</td>
<td>
<em>(Optional)</em>
<p>Whether the nodes will be automatically repaired.</p>
</td>
</tr>
<tr>
<td>
<code>autoUpgrade</code><br/>
<em>
bool
</em>
</td>
<td>
<em>(Optional)</em>
<p>Whether the nodes will be automatically upgraded.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="container.google.kubeform.com/v1alpha1.NodePoolSpecNodeConfig">NodePoolSpecNodeConfig
</h3>
<p>
(<em>Appears on:</em><a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecResource">NodePoolSpecResource</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>diskSizeGb</code><br/>
<em>
int64
</em>
</td>
<td>
<em>(Optional)</em>
<p>Size of the disk attached to each node, specified in GB. The smallest allowed disk size is 10GB.</p>
</td>
</tr>
<tr>
<td>
<code>diskType</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Type of the disk attached to each node.</p>
</td>
</tr>
<tr>
<td>
<code>guestAccelerator</code><br/>
<em>
<a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecNodeConfigGuestAccelerator">
[]NodePoolSpecNodeConfigGuestAccelerator
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>List of the type and count of accelerator cards attached to the instance.</p>
</td>
</tr>
<tr>
<td>
<code>imageType</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The image type to use for this node. Note that for a given image type, the latest version of it will be used.</p>
</td>
</tr>
<tr>
<td>
<code>labels</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The map of Kubernetes labels (key/value pairs) to be applied to each node. These will added in addition to any default label(s) that Kubernetes may apply to the node.</p>
</td>
</tr>
<tr>
<td>
<code>localSsdCount</code><br/>
<em>
int64
</em>
</td>
<td>
<em>(Optional)</em>
<p>The number of local SSD disks to be attached to the node.</p>
</td>
</tr>
<tr>
<td>
<code>machineType</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The name of a Google Compute Engine machine type.</p>
</td>
</tr>
<tr>
<td>
<code>metadata</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The metadata key/value pairs assigned to instances in the cluster.</p>
</td>
</tr>
<tr>
<td>
<code>minCPUPlatform</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Minimum CPU platform to be used by this instance. The instance may be scheduled on the specified or newer CPU platform.</p>
</td>
</tr>
<tr>
<td>
<code>oauthScopes</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The set of Google API scopes to be made available on all of the node VMs.</p>
</td>
</tr>
<tr>
<td>
<code>preemptible</code><br/>
<em>
bool
</em>
</td>
<td>
<em>(Optional)</em>
<p>Whether the nodes are created as preemptible VM instances.</p>
</td>
</tr>
<tr>
<td>
<code>serviceAccount</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The Google Cloud Platform Service Account to be used by the node VMs.</p>
</td>
</tr>
<tr>
<td>
<code>shieldedInstanceConfig</code><br/>
<em>
<a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecNodeConfigShieldedInstanceConfig">
NodePoolSpecNodeConfigShieldedInstanceConfig
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Shielded Instance options.</p>
</td>
</tr>
<tr>
<td>
<code>tags</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The list of instance tags applied to all nodes.</p>
</td>
</tr>
<tr>
<td>
<code>taint</code><br/>
<em>
<a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecNodeConfigTaint">
[]NodePoolSpecNodeConfigTaint
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>List of Kubernetes taints to be applied to each node.</p>
</td>
</tr>
<tr>
<td>
<code>workloadMetadataConfig</code><br/>
<em>
<a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecNodeConfigWorkloadMetadataConfig">
NodePoolSpecNodeConfigWorkloadMetadataConfig
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>The workload metadata configuration for this node.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="container.google.kubeform.com/v1alpha1.NodePoolSpecNodeConfigGuestAccelerator">NodePoolSpecNodeConfigGuestAccelerator
</h3>
<p>
(<em>Appears on:</em><a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecNodeConfig">NodePoolSpecNodeConfig</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>count</code><br/>
<em>
int64
</em>
</td>
<td>
<p>The number of the accelerator cards exposed to an instance.</p>
</td>
</tr>
<tr>
<td>
<code>type</code><br/>
<em>
string
</em>
</td>
<td>
<p>The accelerator type resource name.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="container.google.kubeform.com/v1alpha1.NodePoolSpecNodeConfigShieldedInstanceConfig">NodePoolSpecNodeConfigShieldedInstanceConfig
</h3>
<p>
(<em>Appears on:</em><a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecNodeConfig">NodePoolSpecNodeConfig</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>enableIntegrityMonitoring</code><br/>
<em>
bool
</em>
</td>
<td>
<em>(Optional)</em>
<p>Defines whether the instance has integrity monitoring enabled.</p>
</td>
</tr>
<tr>
<td>
<code>enableSecureBoot</code><br/>
<em>
bool
</em>
</td>
<td>
<em>(Optional)</em>
<p>Defines whether the instance has Secure Boot enabled.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="container.google.kubeform.com/v1alpha1.NodePoolSpecNodeConfigTaint">NodePoolSpecNodeConfigTaint
</h3>
<p>
(<em>Appears on:</em><a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecNodeConfig">NodePoolSpecNodeConfig</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>effect</code><br/>
<em>
string
</em>
</td>
<td>
<p>Effect for taint.</p>
</td>
</tr>
<tr>
<td>
<code>key</code><br/>
<em>
string
</em>
</td>
<td>
<p>Key for taint.</p>
</td>
</tr>
<tr>
<td>
<code>value</code><br/>
<em>
string
</em>
</td>
<td>
<p>Value for taint.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="container.google.kubeform.com/v1alpha1.NodePoolSpecNodeConfigWorkloadMetadataConfig">NodePoolSpecNodeConfigWorkloadMetadataConfig
</h3>
<p>
(<em>Appears on:</em><a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecNodeConfig">NodePoolSpecNodeConfig</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>nodeMetadata</code><br/>
<em>
string
</em>
</td>
<td>
<p>NodeMetadata is the configuration for how to expose metadata to the workloads running on the node.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="container.google.kubeform.com/v1alpha1.NodePoolSpecResource">NodePoolSpecResource
</h3>
<p>
(<em>Appears on:</em><a href="#container.google.kubeform.com/v1alpha1.NodePoolSpec">NodePoolSpec</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>timeouts</code><br/>
<em>
kubeform.dev/apimachinery/api/v1alpha1.ResourceTimeout
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>id</code><br/>
<em>
string
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>autoscaling</code><br/>
<em>
<a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecAutoscaling">
NodePoolSpecAutoscaling
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Configuration required by cluster autoscaler to adjust the size of the node pool to the current cluster usage.</p>
</td>
</tr>
<tr>
<td>
<code>cluster</code><br/>
<em>
string
</em>
</td>
<td>
<p>The cluster to create the node pool for. Cluster must be present in location provided for zonal clusters.</p>
</td>
</tr>
<tr>
<td>
<code>initialNodeCount</code><br/>
<em>
int64
</em>
</td>
<td>
<em>(Optional)</em>
<p>The initial number of nodes for the pool. In regional or multi-zonal clusters, this is the number of nodes per zone. Changing this will force recreation of the resource.</p>
</td>
</tr>
<tr>
<td>
<code>instanceGroupUrls</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The resource URLs of the managed instance groups associated with this node pool.</p>
</td>
</tr>
<tr>
<td>
<code>location</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The location (region or zone) of the cluster.</p>
</td>
</tr>
<tr>
<td>
<code>management</code><br/>
<em>
<a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecManagement">
NodePoolSpecManagement
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Node management configuration, wherein auto-repair and auto-upgrade is configured.</p>
</td>
</tr>
<tr>
<td>
<code>maxPodsPerNode</code><br/>
<em>
int64
</em>
</td>
<td>
<em>(Optional)</em>
<p>The maximum number of pods per node in this node pool. Note that this does not work on node pools which are &quot;route-based&quot; - that is, node pools belonging to clusters that do not have IP Aliasing enabled.</p>
</td>
</tr>
<tr>
<td>
<code>name</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The name of the node pool. If left blank, Terraform will auto-generate a unique name.</p>
</td>
</tr>
<tr>
<td>
<code>namePrefix</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Creates a unique name for the node pool beginning with the specified prefix. Conflicts with name.</p>
</td>
</tr>
<tr>
<td>
<code>nodeConfig</code><br/>
<em>
<a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecNodeConfig">
NodePoolSpecNodeConfig
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>The configuration of the nodepool</p>
</td>
</tr>
<tr>
<td>
<code>nodeCount</code><br/>
<em>
int64
</em>
</td>
<td>
<em>(Optional)</em>
<p>The number of nodes per instance group. This field can be used to update the number of nodes per instance group but should not be used alongside autoscaling.</p>
</td>
</tr>
<tr>
<td>
<code>nodeLocations</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The list of zones in which the node pool's nodes should be located. Nodes must be in the region of their regional cluster or in the same region as their cluster's zone for zonal clusters. If unspecified, the cluster-level node_locations will be used.</p>
</td>
</tr>
<tr>
<td>
<code>operation</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
</td>
</tr>
<tr>
<td>
<code>project</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The ID of the project in which to create the node pool. If blank, the provider-configured project will be used.</p>
</td>
</tr>
<tr>
<td>
<code>upgradeSettings</code><br/>
<em>
<a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecUpgradeSettings">
NodePoolSpecUpgradeSettings
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Specify node upgrade settings to change how many nodes GKE attempts to upgrade at once. The number of nodes upgraded simultaneously is the sum of max_surge and max_unavailable. The maximum number of nodes upgraded simultaneously is limited to 20.</p>
</td>
</tr>
<tr>
<td>
<code>version</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The Kubernetes version for the nodes in this pool. Note that if this field and auto_upgrade are both specified, they will fight each other for what the node version should be, so setting both is highly discouraged. While a fuzzy version can be specified, it's recommended that you specify explicit versions as Terraform will see spurious diffs when fuzzy versions are used. See the google_container_engine_versions data source's version_prefix field to approximate fuzzy versions in a Terraform-compatible way.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="container.google.kubeform.com/v1alpha1.NodePoolSpecUpgradeSettings">NodePoolSpecUpgradeSettings
</h3>
<p>
(<em>Appears on:</em><a href="#container.google.kubeform.com/v1alpha1.NodePoolSpecResource">NodePoolSpecResource</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>maxSurge</code><br/>
<em>
int64
</em>
</td>
<td>
<p>The number of additional nodes that can be added to the node pool during an upgrade. Increasing max_surge raises the number of nodes that can be upgraded simultaneously. Can be set to 0 or greater.</p>
</td>
</tr>
<tr>
<td>
<code>maxUnavailable</code><br/>
<em>
int64
</em>
</td>
<td>
<p>The number of nodes that can be simultaneously unavailable during an upgrade. Increasing max_unavailable raises the number of nodes that can be upgraded in parallel. Can be set to 0 or greater.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="container.google.kubeform.com/v1alpha1.NodePoolStatus">NodePoolStatus
</h3>
<p>
(<em>Appears on:</em><a href="#container.google.kubeform.com/v1alpha1.NodePool">NodePool</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>observedGeneration</code><br/>
<em>
int64
</em>
</td>
<td>
<em>(Optional)</em>
<p>Resource generation, which is updated on mutation by the API Server.</p>
</td>
</tr>
<tr>
<td>
<code>phase</code><br/>
<em>
sigs.k8s.io/cli-utils/pkg/kstatus/status.Status
</em>
</td>
<td>
<em>(Optional)</em>
</td>
</tr>
<tr>
<td>
<code>conditions</code><br/>
<em>
[]kmodules.xyz/client-go/api/v1.Condition
</em>
</td>
<td>
<em>(Optional)</em>
</td>
</tr>
</tbody>
</table>
<p><em>
Generated with <code>gen-api-reference-docs</code>
on git commit <code>b0e6535</code>.
</em></p>
