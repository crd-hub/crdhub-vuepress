<h3 id="dataproc.google.kubeform.com/v1alpha1.Job">Job
</h3>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>apiVersion</code><br/>
string</td>
<td>
<code>
dataproc.google.kubeform.com/v1alpha1
</code>
</td>
</tr>
<tr>
<td>
<code>kind</code><br/>
string
</td>
<td><code>Job</code></td>
</tr>
<tr>
<td>
<code>metadata</code><br/>
<em>
<a href="https://v1-21.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.21/#objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
</a>
</em>
</td>
<td>
Refer to the Kubernetes API documentation for the fields of the
<code>metadata</code> field.
</td>
</tr>
<tr>
<td>
<code>spec</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpec">
JobSpec
</a>
</em>
</td>
<td>
<br/>
<br/>
<table>
<tr>
<td>
<code>state</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecResource">
JobSpecResource
</a>
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>resource</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecResource">
JobSpecResource
</a>
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>updatePolicy</code><br/>
<em>
kubeform.dev/apimachinery/api/v1alpha1.UpdatePolicy
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>terminationPolicy</code><br/>
<em>
kubeform.dev/apimachinery/api/v1alpha1.TerminationPolicy
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>providerRef</code><br/>
<em>
<a href="https://v1-21.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.21/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td>
<code>status</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobStatus">
JobStatus
</a>
</em>
</td>
<td>
<br/>
<br/>
<table>
<tr>
<td>
<code>observedGeneration</code><br/>
<em>
int64
</em>
</td>
<td>
<em>(Optional)</em>
<p>Resource generation, which is updated on mutation by the API Server.</p>
</td>
</tr>
<tr>
<td>
<code>phase</code><br/>
<em>
sigs.k8s.io/cli-utils/pkg/kstatus/status.Status
</em>
</td>
<td>
<em>(Optional)</em>
</td>
</tr>
<tr>
<td>
<code>conditions</code><br/>
<em>
[]kmodules.xyz/client-go/api/v1.Condition
</em>
</td>
<td>
<em>(Optional)</em>
</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpec">JobSpec
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.Job">Job</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>state</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecResource">
JobSpecResource
</a>
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>resource</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecResource">
JobSpecResource
</a>
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>updatePolicy</code><br/>
<em>
kubeform.dev/apimachinery/api/v1alpha1.UpdatePolicy
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>terminationPolicy</code><br/>
<em>
kubeform.dev/apimachinery/api/v1alpha1.TerminationPolicy
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>providerRef</code><br/>
<em>
<a href="https://v1-21.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.21/#localobjectreference-v1-core">
Kubernetes core/v1.LocalObjectReference
</a>
</em>
</td>
<td>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecHadoopConfig">JobSpecHadoopConfig
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecResource">JobSpecResource</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>archiveUris</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.</p>
</td>
</tr>
<tr>
<td>
<code>args</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The arguments to pass to the driver.</p>
</td>
</tr>
<tr>
<td>
<code>fileUris</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>HCFS URIs of files to be copied to the working directory of Spark drivers and distributed tasks. Useful for naively parallel tasks.</p>
</td>
</tr>
<tr>
<td>
<code>jarFileUris</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>HCFS URIs of jar files to add to the CLASSPATHs of the Spark driver and tasks.</p>
</td>
</tr>
<tr>
<td>
<code>loggingConfig</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecHadoopConfigLoggingConfig">
JobSpecHadoopConfigLoggingConfig
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>The runtime logging config of the job</p>
</td>
</tr>
<tr>
<td>
<code>mainClass</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The class containing the main method of the driver. Must be in a provided jar or jar that is already on the classpath. Conflicts with main_jar_file_uri</p>
</td>
</tr>
<tr>
<td>
<code>mainJarFileURI</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The HCFS URI of jar file containing the driver jar. Conflicts with main_class</p>
</td>
</tr>
<tr>
<td>
<code>properties</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>A mapping of property names to values, used to configure Spark. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecHadoopConfigLoggingConfig">JobSpecHadoopConfigLoggingConfig
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecHadoopConfig">JobSpecHadoopConfig</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>driverLogLevels</code><br/>
<em>
string
</em>
</td>
<td>
<p>Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecHiveConfig">JobSpecHiveConfig
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecResource">JobSpecResource</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>continueOnFailure</code><br/>
<em>
bool
</em>
</td>
<td>
<em>(Optional)</em>
<p>Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries. Defaults to false.</p>
</td>
</tr>
<tr>
<td>
<code>jarFileUris</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>HCFS URIs of jar files to add to the CLASSPATH of the Hive server and Hadoop MapReduce (MR) tasks. Can contain Hive SerDes and UDFs.</p>
</td>
</tr>
<tr>
<td>
<code>properties</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>A mapping of property names and values, used to configure Hive. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/hive/conf/hive-site.xml, and classes in user code.</p>
</td>
</tr>
<tr>
<td>
<code>queryFileURI</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>HCFS URI of file containing Hive script to execute as the job. Conflicts with query_list</p>
</td>
</tr>
<tr>
<td>
<code>queryList</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The list of Hive queries or statements to execute as part of the job. Conflicts with query_file_uri</p>
</td>
</tr>
<tr>
<td>
<code>scriptVariables</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Mapping of query variable names to values (equivalent to the Hive command: SET name=&quot;value&quot;;).</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecPigConfig">JobSpecPigConfig
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecResource">JobSpecResource</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>continueOnFailure</code><br/>
<em>
bool
</em>
</td>
<td>
<em>(Optional)</em>
<p>Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries. Defaults to false.</p>
</td>
</tr>
<tr>
<td>
<code>jarFileUris</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>HCFS URIs of jar files to add to the CLASSPATH of the Pig Client and Hadoop MapReduce (MR) tasks. Can contain Pig UDFs.</p>
</td>
</tr>
<tr>
<td>
<code>loggingConfig</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecPigConfigLoggingConfig">
JobSpecPigConfigLoggingConfig
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>The runtime logging config of the job</p>
</td>
</tr>
<tr>
<td>
<code>properties</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>A mapping of property names to values, used to configure Pig. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/pig/conf/pig.properties, and classes in user code.</p>
</td>
</tr>
<tr>
<td>
<code>queryFileURI</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>HCFS URI of file containing Hive script to execute as the job. Conflicts with query_list</p>
</td>
</tr>
<tr>
<td>
<code>queryList</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The list of Hive queries or statements to execute as part of the job. Conflicts with query_file_uri</p>
</td>
</tr>
<tr>
<td>
<code>scriptVariables</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Mapping of query variable names to values (equivalent to the Pig command: name=[value]).</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecPigConfigLoggingConfig">JobSpecPigConfigLoggingConfig
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecPigConfig">JobSpecPigConfig</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>driverLogLevels</code><br/>
<em>
string
</em>
</td>
<td>
<p>Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecPlacement">JobSpecPlacement
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecResource">JobSpecResource</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>clusterName</code><br/>
<em>
string
</em>
</td>
<td>
<p>The name of the cluster where the job will be submitted</p>
</td>
</tr>
<tr>
<td>
<code>clusterUUID</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Output-only. A cluster UUID generated by the Cloud Dataproc service when the job is submitted</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecPysparkConfig">JobSpecPysparkConfig
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecResource">JobSpecResource</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>archiveUris</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Optional. HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip</p>
</td>
</tr>
<tr>
<td>
<code>args</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Optional. The arguments to pass to the driver. Do not include arguments, such as --conf, that can be set as job properties, since a collision may occur that causes an incorrect job submission</p>
</td>
</tr>
<tr>
<td>
<code>fileUris</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Optional. HCFS URIs of files to be copied to the working directory of Python drivers and distributed tasks. Useful for naively parallel tasks</p>
</td>
</tr>
<tr>
<td>
<code>jarFileUris</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Optional. HCFS URIs of jar files to add to the CLASSPATHs of the Python driver and tasks</p>
</td>
</tr>
<tr>
<td>
<code>loggingConfig</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecPysparkConfigLoggingConfig">
JobSpecPysparkConfigLoggingConfig
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>The runtime logging config of the job</p>
</td>
</tr>
<tr>
<td>
<code>mainPythonFileURI</code><br/>
<em>
string
</em>
</td>
<td>
<p>Required. The HCFS URI of the main Python file to use as the driver. Must be a .py file</p>
</td>
</tr>
<tr>
<td>
<code>properties</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Optional. A mapping of property names to values, used to configure PySpark. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code</p>
</td>
</tr>
<tr>
<td>
<code>pythonFileUris</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Optional. HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecPysparkConfigLoggingConfig">JobSpecPysparkConfigLoggingConfig
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecPysparkConfig">JobSpecPysparkConfig</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>driverLogLevels</code><br/>
<em>
string
</em>
</td>
<td>
<p>Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecReference">JobSpecReference
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecResource">JobSpecResource</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>jobID</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The job ID, which must be unique within the project. The job ID is generated by the server upon job submission or provided by the user as a means to perform retries without creating duplicate jobs</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecResource">JobSpecResource
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpec">JobSpec</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>timeouts</code><br/>
<em>
kubeform.dev/apimachinery/api/v1alpha1.ResourceTimeout
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>id</code><br/>
<em>
string
</em>
</td>
<td>
</td>
</tr>
<tr>
<td>
<code>driverControlsFilesURI</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Output-only. If present, the location of miscellaneous control files which may be used as part of job setup and handling. If not present, control files may be placed in the same location as driver_output_uri.</p>
</td>
</tr>
<tr>
<td>
<code>driverOutputResourceURI</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Output-only. A URI pointing to the location of the stdout of the job's driver program</p>
</td>
</tr>
<tr>
<td>
<code>forceDelete</code><br/>
<em>
bool
</em>
</td>
<td>
<em>(Optional)</em>
<p>By default, you can only delete inactive jobs within Dataproc. Setting this to true, and calling destroy, will ensure that the job is first cancelled before issuing the delete.</p>
</td>
</tr>
<tr>
<td>
<code>hadoopConfig</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecHadoopConfig">
JobSpecHadoopConfig
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>The config of Hadoop job</p>
</td>
</tr>
<tr>
<td>
<code>hiveConfig</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecHiveConfig">
JobSpecHiveConfig
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>The config of hive job</p>
</td>
</tr>
<tr>
<td>
<code>labels</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Optional. The labels to associate with this job.</p>
</td>
</tr>
<tr>
<td>
<code>pigConfig</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecPigConfig">
JobSpecPigConfig
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>The config of pag job.</p>
</td>
</tr>
<tr>
<td>
<code>placement</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecPlacement">
JobSpecPlacement
</a>
</em>
</td>
<td>
<p>The config of job placement.</p>
</td>
</tr>
<tr>
<td>
<code>project</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The project in which the cluster can be found and jobs subsequently run against. If it is not provided, the provider project is used.</p>
</td>
</tr>
<tr>
<td>
<code>pysparkConfig</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecPysparkConfig">
JobSpecPysparkConfig
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>The config of pySpark job.</p>
</td>
</tr>
<tr>
<td>
<code>reference</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecReference">
JobSpecReference
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>The reference of the job</p>
</td>
</tr>
<tr>
<td>
<code>region</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The Cloud Dataproc region. This essentially determines which clusters are available for this job to be submitted to. If not specified, defaults to global.</p>
</td>
</tr>
<tr>
<td>
<code>scheduling</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecScheduling">
JobSpecScheduling
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>Optional. Job scheduling configuration.</p>
</td>
</tr>
<tr>
<td>
<code>sparkConfig</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecSparkConfig">
JobSpecSparkConfig
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>The config of the Spark job.</p>
</td>
</tr>
<tr>
<td>
<code>sparksqlConfig</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecSparksqlConfig">
JobSpecSparksqlConfig
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>The config of SparkSql job</p>
</td>
</tr>
<tr>
<td>
<code>status</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecStatus">
[]JobSpecStatus
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>The status of the job.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecScheduling">JobSpecScheduling
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecResource">JobSpecResource</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>maxFailuresPerHour</code><br/>
<em>
int64
</em>
</td>
<td>
<p>Maximum number of times per hour a driver may be restarted as a result of driver exiting with non-zero code before job is reported failed.</p>
</td>
</tr>
<tr>
<td>
<code>maxFailuresTotal</code><br/>
<em>
int64
</em>
</td>
<td>
<p>Maximum number of times in total a driver may be restarted as a result of driver exiting with non-zero code before job is reported failed.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecSparkConfig">JobSpecSparkConfig
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecResource">JobSpecResource</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>archiveUris</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.</p>
</td>
</tr>
<tr>
<td>
<code>args</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The arguments to pass to the driver.</p>
</td>
</tr>
<tr>
<td>
<code>fileUris</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>HCFS URIs of files to be copied to the working directory of Spark drivers and distributed tasks. Useful for naively parallel tasks.</p>
</td>
</tr>
<tr>
<td>
<code>jarFileUris</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>HCFS URIs of jar files to add to the CLASSPATHs of the Spark driver and tasks.</p>
</td>
</tr>
<tr>
<td>
<code>loggingConfig</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecSparkConfigLoggingConfig">
JobSpecSparkConfigLoggingConfig
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>The runtime logging config of the job</p>
</td>
</tr>
<tr>
<td>
<code>mainClass</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The class containing the main method of the driver. Must be in a provided jar or jar that is already on the classpath. Conflicts with main_jar_file_uri</p>
</td>
</tr>
<tr>
<td>
<code>mainJarFileURI</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The HCFS URI of jar file containing the driver jar. Conflicts with main_class</p>
</td>
</tr>
<tr>
<td>
<code>properties</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>A mapping of property names to values, used to configure Spark. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecSparkConfigLoggingConfig">JobSpecSparkConfigLoggingConfig
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecSparkConfig">JobSpecSparkConfig</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>driverLogLevels</code><br/>
<em>
string
</em>
</td>
<td>
<p>Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecSparksqlConfig">JobSpecSparksqlConfig
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecResource">JobSpecResource</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>jarFileUris</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>HCFS URIs of jar files to be added to the Spark CLASSPATH.</p>
</td>
</tr>
<tr>
<td>
<code>loggingConfig</code><br/>
<em>
<a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecSparksqlConfigLoggingConfig">
JobSpecSparksqlConfigLoggingConfig
</a>
</em>
</td>
<td>
<em>(Optional)</em>
<p>The runtime logging config of the job</p>
</td>
</tr>
<tr>
<td>
<code>properties</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.</p>
</td>
</tr>
<tr>
<td>
<code>queryFileURI</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The HCFS URI of the script that contains SQL queries. Conflicts with query_list</p>
</td>
</tr>
<tr>
<td>
<code>queryList</code><br/>
<em>
[]string
</em>
</td>
<td>
<em>(Optional)</em>
<p>The list of SQL queries or statements to execute as part of the job. Conflicts with query_file_uri</p>
</td>
</tr>
<tr>
<td>
<code>scriptVariables</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Mapping of query variable names to values (equivalent to the Spark SQL command: SET name=&quot;value&quot;;).</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecSparksqlConfigLoggingConfig">JobSpecSparksqlConfigLoggingConfig
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecSparksqlConfig">JobSpecSparksqlConfig</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>driverLogLevels</code><br/>
<em>
string
</em>
</td>
<td>
<p>Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobSpecStatus">JobSpecStatus
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.JobSpecResource">JobSpecResource</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>details</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Output-only. Optional job state details, such as an error description if the state is ERROR</p>
</td>
</tr>
<tr>
<td>
<code>state</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Output-only. A state message specifying the overall job state</p>
</td>
</tr>
<tr>
<td>
<code>stateStartTime</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Output-only. The time when this state was entered</p>
</td>
</tr>
<tr>
<td>
<code>substate</code><br/>
<em>
string
</em>
</td>
<td>
<em>(Optional)</em>
<p>Output-only. Additional state information, which includes status reported by the agent</p>
</td>
</tr>
</tbody>
</table>
<h3 id="dataproc.google.kubeform.com/v1alpha1.JobStatus">JobStatus
</h3>
<p>
(<em>Appears on:</em><a href="#dataproc.google.kubeform.com/v1alpha1.Job">Job</a>)
</p>
<div>
</div>
<table>
<thead>
<tr>
<th>Field</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<code>observedGeneration</code><br/>
<em>
int64
</em>
</td>
<td>
<em>(Optional)</em>
<p>Resource generation, which is updated on mutation by the API Server.</p>
</td>
</tr>
<tr>
<td>
<code>phase</code><br/>
<em>
sigs.k8s.io/cli-utils/pkg/kstatus/status.Status
</em>
</td>
<td>
<em>(Optional)</em>
</td>
</tr>
<tr>
<td>
<code>conditions</code><br/>
<em>
[]kmodules.xyz/client-go/api/v1.Condition
</em>
</td>
<td>
<em>(Optional)</em>
</td>
</tr>
</tbody>
</table>
<p><em>
Generated with <code>gen-api-reference-docs</code>
on git commit <code>b0e6535</code>.
</em></p>
